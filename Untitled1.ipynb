{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GaussianNoise\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers, metrics\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import LSTM\n",
    "import csv\n",
    "from preprocess import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 32\n",
    "TIMESTEPS = 24\n",
    "EPOCH = 500\n",
    "PATIENCE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../trading-wind-energy/average-wind-speed.csv')\n",
    "speeds = df['Average Speed (m/s)']\n",
    "\n",
    "# Get energy production data\n",
    "df_energy = pd.read_csv('../trading-wind-energy/energy-interpolated.csv')\n",
    "energys = df_energy['Energy Prooduction (kWh)'].to_numpy().reshape(-1, 1)\n",
    "scaler_energys = MinMaxScaler()\n",
    "scaler_energys.fit(energys)\n",
    "energys_scaled = scaler_energys.transform(energys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shifted energy production data\n",
    "num_inputs = energys_scaled.shape[0]\n",
    "energys_shifted = df_energy['Energy Prooduction (kWh)'].shift(\n",
    "    periods=-18)[TIMESTEPS-1:num_inputs-18].to_numpy().reshape(-1, 1)\n",
    "scaler_energys_shifted = MinMaxScaler()\n",
    "scaler_energys.fit(energys_shifted)\n",
    "energys_shifted_scaled = scaler_energys.transform(energys_shifted)\n",
    "# print(\"e shifted\" + str(energys_shifted[:20, 0]))\n",
    "# print(energys_shifted.shape)\n",
    "# print(\"e shifted\" + str(energys_shifted[30810:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get wind speed data\n",
    "df_speed = pd.read_csv('../trading-wind-energy/average-wind-speed.csv')\n",
    "speeds = df_speed['Average Speed (m/s)'].to_numpy().reshape(-1, 1)\n",
    "scaler_speed = MinMaxScaler()\n",
    "scaler_speed.fit(speeds)\n",
    "speeds_scaled = scaler_speed.transform(speeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.10876672]\n",
      " [0.         0.117649  ]\n",
      " [0.         0.12653129]\n",
      " [0.         0.13541357]\n",
      " [0.         0.14429586]\n",
      " [0.         0.15317814]\n",
      " [0.         0.16206043]\n",
      " [0.         0.17686974]\n",
      " [0.         0.19167905]\n",
      " [0.         0.20648836]]\n",
      "x(30850, 2)\n"
     ]
    }
   ],
   "source": [
    "# Combine energy and speed\n",
    "x = np.empty((num_inputs, 2))\n",
    "for i in range(num_inputs):\n",
    "    x[i] = np.append(energys_scaled[i], speeds_scaled[i])\n",
    "print(x[:10])\n",
    "print(\"x\" + str(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.24666667]\n",
      " [1.3675    ]\n",
      " [1.48833333]\n",
      " [1.60916667]\n",
      " [1.73      ]\n",
      " [1.81270833]\n",
      " [1.89541667]\n",
      " [1.978125  ]\n",
      " [2.06083333]\n",
      " [2.14354167]\n",
      " [2.22625   ]\n",
      " [2.2675    ]\n",
      " [2.30875   ]\n",
      " [2.35      ]\n",
      " [2.39125   ]\n",
      " [2.4325    ]\n",
      " [2.47375   ]\n",
      " [2.39424242]\n",
      " [2.31473485]\n",
      " [2.23522727]\n",
      " [2.1557197 ]\n",
      " [2.07621212]\n",
      " [1.99670455]\n",
      " [2.31157197]\n",
      " [2.62643939]\n",
      " [2.94130682]\n",
      " [3.25617424]\n",
      " [3.57104167]\n",
      " [3.88590909]\n",
      " [3.67556818]\n",
      " [3.46522727]\n",
      " [3.25488636]\n",
      " [3.04454545]]\n",
      "energy:\n",
      "[[ 5500.]\n",
      " [ 6000.]\n",
      " [ 5750.]\n",
      " [ 5250.]\n",
      " [ 5250.]\n",
      " [ 5000.]\n",
      " [ 5250.]\n",
      " [ 5250.]\n",
      " [ 5750.]\n",
      " [ 5250.]\n",
      " [ 5750.]\n",
      " [ 5500.]\n",
      " [ 6750.]\n",
      " [ 9500.]\n",
      " [13500.]\n",
      " [19000.]\n",
      " [29750.]\n",
      " [25000.]\n",
      " [14500.]\n",
      " [ 7000.]\n",
      " [ 5750.]\n",
      " [ 6000.]\n",
      " [ 5750.]\n",
      " [ 5250.]\n",
      " [ 5250.]\n",
      " [ 6250.]\n",
      " [10000.]\n",
      " [12000.]\n",
      " [15000.]\n",
      " [15000.]\n",
      " [13250.]\n",
      " [14000.]\n",
      " [15500.]]\n",
      "y\n",
      "[[ 5750.]\n",
      " [ 6000.]\n",
      " [ 5750.]\n",
      " [ 5250.]\n",
      " [ 5250.]\n",
      " [ 6250.]\n",
      " [10000.]\n",
      " [12000.]\n",
      " [15000.]\n",
      " [15000.]\n",
      " [13250.]\n",
      " [14000.]\n",
      " [15500.]\n",
      " [12500.]\n",
      " [14750.]\n",
      " [12250.]\n",
      " [10250.]\n",
      " [11250.]\n",
      " [14250.]\n",
      " [13000.]\n",
      " [10250.]\n",
      " [ 5250.]\n",
      " [ 6250.]\n",
      " [ 6250.]\n",
      " [ 5500.]\n",
      " [ 6000.]\n",
      " [ 6000.]\n",
      " [ 6000.]\n",
      " [ 6000.]\n",
      " [ 5000.]]\n"
     ]
    }
   ],
   "source": [
    "# Transform\n",
    "x_transformed = []\n",
    "for i in range(TIMESTEPS, num_inputs):\n",
    "    x_transformed.append(x[i-TIMESTEPS:i, :])\n",
    "x_transformed = np.array(x_transformed)\n",
    "# print(x_transformed[:10])\n",
    "# print(\"x_transformed\" + str(x_transformed.shape))\n",
    "# print(x_transformed[x_transformed.shape[0]-40:x_transformed.shape[0]-17])\n",
    "print(speeds[-50:-17])\n",
    "print(\"energy:\")\n",
    "print(energys[-50:-17])\n",
    "print(\"y\")\n",
    "print(energys_shifted[-30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_transformed[:-17], energys_shifted_scaled, test_size=0.2, random_state=0)\n",
    "\n",
    "n_features = 1\n",
    "# X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "# X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 48)                9792      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                1764      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                888       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 12,469\n",
      "Trainable params: 12,469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(48,  activation='tanh', input_shape=(\n",
    "    TIMESTEPS, 2), return_sequences=False))\n",
    "model.add(Dense(36, activation='relu', input_dim=96))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "# model.add(LSTM(24, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "es = EarlyStopping(monitor='val_loss', patience=PATIENCE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/envs/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 19717 samples, validate on 4930 samples\n",
      "Epoch 1/500\n",
      "19717/19717 [==============================] - 38s 2ms/step - loss: 0.0327 - val_loss: 0.0311\n",
      "Epoch 2/500\n",
      " 7136/19717 [=========>....................] - ETA: 20s - loss: 0.0309"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-782307bf4e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(X_train, y_train, epochs=EPOCH,\n\u001b[0;32m----> 3\u001b[0;31m                     validation_split=0.2, batch_size=BATCH_SIZE, callbacks=[es])\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/Applications/anaconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=EPOCH,\n",
    "                    validation_split=0.2, batch_size=BATCH_SIZE, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graphs regarding the results\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('Train and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "print('Evaluate on test data')\n",
    "results = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "print('Test loss: ', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "print('Generating Predictions')\n",
    "predictions_array = model.predict(\n",
    "    X_test, batch_size=32, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actuals\n",
    "plt.plot(predictions_array[700:1000], label='predictions')\n",
    "plt.plot(y_test[700:1000], label='actuals')\n",
    "plt.legend()\n",
    "plt.title('Predictions vs Actuals - First 1000')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test particular prediction\n",
    "# x = 1210\n",
    "# print(X_energyDataWithWindow[x])\n",
    "# data = scaler_x.transform([X_energyDataWithWindow[x]])\n",
    "# data = data.reshape(1, WINDOW_SIZE*2, 1)\n",
    "# datay = model.predict(data)\n",
    "# print(scaler_y.inverse_transform(datay))\n",
    "# print(Y_energyDataWithWindow[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('venv': conda)",
   "language": "python",
   "name": "python37664bitvenvconda3dcb4ed2e81b44da81ab44b28ad3c6d6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
